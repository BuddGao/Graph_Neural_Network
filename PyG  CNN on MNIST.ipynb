{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import sklearn.metrics as metrics\n",
    "BATCH_SIZE = 32\n",
    "#transformations\n",
    "transform = transforms.Compose([transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                     download=True, transform=transform)\n",
    "trainloader= torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                     download=True, transform=transform)\n",
    "testloader= torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        \n",
    "        #28x28x1 => 26x26x32\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3)\n",
    "        self.d1 = nn.Linear(26 * 26 * 32, 128)\n",
    "        self.d2 = nn.Linear(128, 10)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        #32x1x28x28 => 32x32x26x26\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        #flatten => 32x(32*26*26)\n",
    "        x = x.flatten(start_dim = 1)\n",
    "        \n",
    "        #32x(32*26*26) => 32x128\n",
    "        x = self.d1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        #logits => 32x10\n",
    "        logits = self.d2(x)\n",
    "        out = F.softmax(logits, dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.array([[1,2],[3,4]])\n",
    "b = np.ones((2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3.],\n",
      "        [7., 7.]], device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "ta = torch.tensor(a, dtype=float).cuda()\n",
    "tb = torch.tensor(b, dtype=float).cuda()\n",
    "print(torch.matmul(ta,tb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "num_epochs = 5\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MyModel()\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Loss:  1.4729 | Train Accuracy:  0.99\n",
      "Epoch: 1 | Loss:  1.4707 | Train Accuracy:  0.99\n",
      "Epoch: 2 | Loss:  1.4695 | Train Accuracy:  0.99\n",
      "Epoch: 3 | Loss:  1.4682 | Train Accuracy:  0.99\n",
      "Epoch: 4 | Loss:  1.4680 | Train Accuracy:  0.99\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    train_running_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    \n",
    "    # training step\n",
    "    for i,(images, labels) in enumerate(trainloader):\n",
    "        \n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        ##forward + backprop + loss\n",
    "        logits = model(images)\n",
    "        loss = criterion(logits, labels)\n",
    "        optimizer.zero_grad() #归零防止叠加\n",
    "        loss.backward()\n",
    "        \n",
    "        ##update model params\n",
    "        optimizer.step()\n",
    "        train_running_loss += loss.detach().item()\n",
    "        \n",
    "        ###取最大值（最大可能性）为label判断是否与y相等\n",
    "        train_acc += (torch.argmax(logits,1).flatten() == labels).type(torch.float).mean().item()\n",
    "    \n",
    "    #换行时分隔符\\ 后面不能有空格\n",
    "    print('Epoch: %d | Loss: % .4f | Train Accuracy: % .2f'\\\n",
    "          %(epoch, train_running_loss / i, train_acc/i))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.99\n"
     ]
    }
   ],
   "source": [
    "test_acc = 0.0\n",
    "for i, (images, labels) in enumerate(testloader, 0):\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    outputs = model(images)\n",
    "    test_acc += (torch.argmax(outputs,1).flatten() == labels).type(torch.float).mean().item()\n",
    "print('Test Accuracy: %.2f'%(test_acc/i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
